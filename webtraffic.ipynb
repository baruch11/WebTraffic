{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "%config Completer.use_jedi = False  # to make autocompletion faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gc\n",
    "%matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!kaggle competitions download -c web-traffic-time-series-forecasting\n",
    "!yes|unzip web-traffic-time-series-forecasting.zip\n",
    "!mkdir logs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from webtraffic_utils import *\n",
    "output_len = 62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features like (access, spectral tones) created by feature_engineering.ipynb\n",
    "\n",
    "from ast import literal_eval\n",
    "df_feat = pd.read_csv(\"features_computed.csv.zip\",converters={\"tones\":literal_eval}).set_index(\"Page\")\n",
    "weekly_tone = df_feat[\"tones\"].apply(lambda x: (np.abs(np.array(x)-1./7.)<1e-2).any()).rename(\"week\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ds = pd.read_csv(\"train_2.csv.zip\", header=0).set_index(\"Page\").fillna(0).astype(np.int32)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# add features to df\n",
    "add_feats = pd.concat([weekly_tone], axis=1)\n",
    "add_feats.rename(columns={ii:\"feat_\"+str(ii) for ii in add_feats.columns}, inplace=True)\n",
    "df_ds = pd.concat([df_ds, add_feats], axis=1)\n",
    "add_feats.columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test, week_train, week_test = train_test_split(df_ds, weekly_tone, test_size=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[repeat last value](#repeat-last-value)  \n",
    "[linear model](#linear-model)  \n",
    "[RNN](#RNN)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat[\"access\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remarkable pages\n",
    "\n",
    "rem_pages = [\n",
    "    'Acier_inoxydable_fr.wikipedia.org_desktop_all-agents',\n",
    "]\n",
    "#rem_pages = df_ds.loc[weekly_tone & (df_feat[\"access\"] == \"desktop_all-agents\")].index\n",
    "\n",
    "\n",
    "\n",
    "page = rem_pages[0]\n",
    "traffic_t =  df_ds.loc[page].values[:-1].astype(int)\n",
    "f,vax = plt.subplots(1,3, figsize=(20,4))\n",
    "fax = vax.flat\n",
    "\n",
    "\n",
    "ax=next(fax)\n",
    "ax.plot(traffic_t)\n",
    "ax.set_title(\"time traffic\")\n",
    "\n",
    "\n",
    "ax=next(fax)\n",
    "ax.plot(estimated_autocorrelation(traffic_t))\n",
    "ax.set_xticks([0,365,2*365])\n",
    "ax.set_title(\"autocorrelation\")\n",
    "ax.grid()\n",
    "\n",
    "ax=next(fax)\n",
    "plot_spectrest(traffic_t, ax)\n",
    "ax.set_title(\"spectral estimation\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.suptitle(page, fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[repeat last value](#repeat-last-value)  \n",
    "[linear model](#linear-model)  \n",
    "[RNN](#RNN)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### repeat last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp\n",
    "\n",
    "class Median(tf.keras.layers.Layer):\n",
    "    def __init__(self, median_depth=40):\n",
    "        super().__init__()\n",
    "        self.median_depth =median_depth\n",
    "            \n",
    "    def call(self, inputs):\n",
    "        #print(inputs)\n",
    "        Xtraff = tfp.stats.percentile(inputs[:,-self.median_depth:], 50.0, \n",
    "                                      interpolation='lower', axis=1)\n",
    "        return tf.tile(tf.expand_dims(Xtraff,axis=1), [1,output_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "I_traffic = tf.keras.layers.Input(shape=(None,))\n",
    "I_page = tf.keras.layers.Input(shape=(), dtype=object)\n",
    "outputs = Median(40)(I_traffic)  \n",
    "med = tf.keras.models.Model([I_page,I_traffic],outputs)\n",
    "\n",
    "med.compile(loss=SmapeLoss(), metrics=[SmapeMetric()])\n",
    "\n",
    "features, target = get_model_inputs(df_ds)\n",
    "med.evaluate(features, target, batch_size=1000)\n",
    "\n",
    "med.save(\"saved_model/median\", save_format='tf')\n",
    "_=gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = get_model_inputs(df_ds.loc[~weekly_tone])\n",
    "med.evaluate(features, target, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_check_result(df_ds, rem_pages[0], [med])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.05)\n",
    "lr_cb = tf.keras.callbacks.LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tb_cb = create_tb_cb(\"linear\")\n",
    "Ldelay=100\n",
    "\n",
    "traffic = tf.keras.layers.Input(shape=(1000,))\n",
    "page = tf.keras.layers.Input(shape=())\n",
    "\n",
    "outputs = tf.keras.layers.Dense(units=output_len,input_dim=Ldelay)(traffic[:,-Ldelay:])\n",
    "\n",
    "model_linear = tf.keras.Model(inputs=[page, traffic], outputs=[outputs])\n",
    "\n",
    "model_linear.summary()\n",
    "\n",
    "model_linear.compile(loss=SmapeLoss(), optimizer=tf.optimizers.Adam(learning_rate=1e-4), \n",
    "                     metrics=[SmapeMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_cb = tf.keras.callbacks.EarlyStopping(monitor='smape', min_delta=0.1, patience=5, verbose=0, restore_best_weights=True)\n",
    "\n",
    "#ds1.cache()\n",
    "features, target = get_model_inputs(df_ds[weekly_tone])\n",
    "feat_val, target_val = get_model_inputs(df_ds.iloc[:,:-50][weekly_tone])\n",
    "model_linear.fit(features, target, epochs=100, callbacks=[tb_cb, es_cb], batch_size=32, validation_data=(feat_val, target_val))\n",
    "model_linear.save(\"saved_model/model_linear_nw\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_check_result(df_ds, rem_pages[0], [model_linear, med])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model_linear.get_layer(\"dense\").get_weights()[0]\n",
    "\n",
    "f,ax = plt.subplots()\n",
    "ax.plot(np.abs(weights[:,0]))\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mixed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_row(df_train, model):\n",
    "    features, ytrue = get_model_inputs(df_train)\n",
    "    def _smape_row(A, F):\n",
    "        return np.mean(100 * (2 * np.abs(F - A) / (np.abs(A) + np.abs(F) + np.finfo(float).eps)), axis=1)\n",
    "    return pd.Series(_smape_row(model.predict(features, batch_size=1000, verbose=1), ytrue), index=df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best choice between linear and median\n",
    "cv_sz = 1\n",
    "decal = 162\n",
    "\n",
    "best_accu = pd.Series(0, index=df_ds.index)\n",
    "for ii in range(cv_sz):\n",
    "    last_samp = df_ds.shape[1]-1-ii*decal\n",
    "    df_train = df_ds.iloc[:,last_samp-decal:last_samp]\n",
    "    smape_lin = smape_row(df_train, model_linear).rename(\"smape_lin\")\n",
    "    smape_med = smape_row(df_train, med).rename(\"smape_med\")\n",
    "    print(\"fold : {}, mixed smape : {:.1f}\".format( ii, pd.concat([smape_lin, smape_med], axis=1).min(axis=1).mean()))\n",
    "    best_accu = best_accu + (pd.concat([smape_lin, smape_med], axis=1).idxmin(axis=1) == \"smape_med\").astype(float)/cv_sz\n",
    "    \n",
    "_ = gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_en = best_accu > 0.5\n",
    "smape_lin = smape_row(df_ds.iloc[:,:], model_linear).rename(\"smape_lin\")\n",
    "smape_med = smape_row(df_ds.iloc[:,:], med).rename(\"smape_med\")\n",
    "smape_mixed = smape_med* median_en + smape_lin * (1-median_en)\n",
    "smape_mixed.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "tb_cb = create_tb_cb(\"mixed\")\n",
    "\n",
    "traffic = tf.keras.layers.Input(shape=(1000,))\n",
    "page = tf.keras.layers.Input(shape=())\n",
    "algo_select = tf.keras.layers.Input(shape=())\n",
    "o_lin = model_linear.get_layer(\"dense\")(traffic[:,-Ldelay:])\n",
    "o_med = Median(40)(traffic)\n",
    "    \n",
    "outputs =  o_lin * tf.tile(tf.expand_dims(tf.cast(1-algo_select, o_lin.dtype),1),[1,62])\n",
    "outputs =  outputs + o_med * tf.tile(tf.expand_dims(tf.cast(algo_select, o_lin.dtype),1),[1,62])\n",
    "\n",
    "    \n",
    "mixed_model = tf.keras.Model(inputs=[page, traffic, algo_select], outputs=[outputs])\n",
    "\n",
    "mixed_model.compile(loss=SmapeLoss(), optimizer=tf.optimizers.Adam(learning_rate=1e-4), \n",
    "                     metrics=[SmapeMetric()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target = get_model_inputs(df_ds.join(median_en.rename(\"feat_select\")))\n",
    "mixed_model.evaluate(features,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_model.save(\"saved_model/mixed_model\", save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_check_result(df_ds.join(median_en.rename(\"feat_select\")), rem_pages[0], [mixed_model, med])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm -Rf logs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nneurons = 20\n",
    "Nlayers = 1\n",
    "MaxTs = 150\n",
    "usePastYear = False\n",
    "useMetadata = False\n",
    "Seq2seq = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class normalize_rnn(tf.keras.layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        fact = tf.reduce_max(inputs, axis=1, keepdims=True)\n",
    "        ret = tf.divide(inputs, fact + 1e-10) \n",
    "        return ret, fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_access = np.unique(df_ds.index.map(lambda x: \"_\".join(x.split(\"_\")[-2:])))\n",
    "voc_project = np.unique(df_ds.index.map(lambda x: x.split(\"_\")[-3]))\n",
    "onehotAccess = OneHotEncodingLayer(voc_access, name=\"ohAccess\")\n",
    "onehotProject = OneHotEncodingLayer(voc_project, name=\"ohProject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "simn = 'Ts'+str(MaxTs)+'-Nn'+str(Nneurons)+'-Nl'+str(Nlayers)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tb_cb = create_tb_cb(simn)\n",
    "\n",
    "class preprocessing_rnn(tf.keras.layers.Layer):\n",
    "    def call(self, inputs, access1h):\n",
    "        ret = inputs[:,-MaxTs:,np.newaxis]\n",
    "        if useMetadata:\n",
    "            access_broadcast = tf.tile(access1h[:,np.newaxis,:],[1,MaxTs,1])\n",
    "            ret = tf.concat([ret, access_broadcast], axis=2)\n",
    "            \n",
    "        if usePastYear:\n",
    "            pastYear = inputs[:, -MaxTs-365+output_len:-365+output_len, np.newaxis]\n",
    "            ret = tf.concat([ret, pastYear], axis=2)\n",
    "        return ret\n",
    "\n",
    "I_page = tf.keras.layers.Input(shape=(), dtype=object)\n",
    "I_traffic = tf.keras.layers.Input(shape=(None,))\n",
    "weekly = tf.keras.layers.Input(shape=())\n",
    "\n",
    "access1h = onehotAccess(I_page)\n",
    "\n",
    "x, factors = normalize_rnn()(I_traffic)\n",
    "x = preprocessing_rnn()(x, access1h)\n",
    "for ii in range(Nlayers-1):\n",
    "    x = tf.keras.layers.GRU(Nneurons, return_sequences=True)(x)\n",
    "x = tf.keras.layers.GRU(Nneurons, return_sequences=Seq2seq>0)(x)\n",
    "\n",
    "if not Seq2seq:\n",
    "    x= tf.keras.layers.Dense(output_len)(x)\n",
    "else:\n",
    "    x = keras.layers.TimeDistributed(keras.layers.Dense(output_len))(x)\n",
    "    factors = tf.cast(tf.tile(tf.expand_dims(factors, axis=1), (1, MaxTs, output_len)), tf.float32)\n",
    "\n",
    "outputs= tf.multiply(x, factors)\n",
    "\n",
    "model_rnn = tf.keras.Model(inputs=[I_page, I_traffic, weekly], outputs=[outputs])\n",
    "\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.compile(loss=SmapeLoss(), optimizer=tf.optimizers.Adam(learning_rate=1e-3), metrics=[SmapeMetric()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3711/17323 [=====>........................] - ETA: 5:06 - loss: 30.6071 - smape: 30.6936"
     ]
    }
   ],
   "source": [
    "es_cb = tf.keras.callbacks.EarlyStopping(monitor='smape', min_delta=0.1, patience=5, verbose=0, restore_best_weights=True)\n",
    "\n",
    "weekly_pages = df_ds.loc[weekly_tone & (df_feat[\"access\"] == \"desktop_all-agents\")].index\n",
    "\n",
    "features, target = get_model_inputs(df_ds.iloc[:,:-62].loc[weekly_tone], return_seq=Seq2seq)\n",
    "feat_val, target_val = get_model_inputs(df_ds.loc[weekly_tone], return_seq=Seq2seq)\n",
    "\n",
    "model_rnn.fit(features, target, epochs=100, callbacks=[tb_cb, es_cb] , batch_size=1, validation_data=(feat_val, target_val))\n",
    "\n",
    "del feat_val, target_val, features, target\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def chunk_smape(df_ds, chunk=10000):\n",
    "    smape_v=[]\n",
    "    for ii in tqdm(range(len(df_ds)//chunk+1)):\n",
    "        features, target = get_model_inputs(df_ds.iloc[ii*chunk:(ii+1)*chunk,:], return_seq=False)\n",
    "        smape_v.append(SmapeLoss()(model_rnn.predict(features, batch_size=1000)[:,-1,:], target).numpy())\n",
    "    return np.mean(smape_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_smape(df_ds.loc[~weekly_tone])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn.save(\"saved_model/model_rnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_check_result(df_ds.iloc[:,:], rem_pages[0], [model_rnn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ouput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = pd.read_csv(\"key_2.csv.zip\").set_index(\"Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key[\"Visits\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_form(features, _model=None):\n",
    "    \"\"\" return a serie indexed by Page \"\"\"\n",
    "    out_date = pd.date_range(start=\"2017-09-13\", end=\"2017-11-13\", freq=\"1D\").strftime(\"%Y-%m-%d\").to_list()\n",
    "    num_pred = np.clip(_model.predict(features, batch_size=1000, verbose=1).astype(int), a_min=0, a_max=None)\n",
    "    index = df_ds.index  # np.char.decode(features[0].numpy().astype(bytes))\n",
    "    ret = pd.DataFrame(num_pred, columns=out_date, index=index).stack().rename(\"Visits\")\n",
    "    ret.index = [ii[0]+\"_\"+ii[1] for ii in ret.index]\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_form(features, _model=None):\n",
    "    \"\"\" return a serie indexed by Page \"\"\"\n",
    "    out_date = pd.date_range(start=\"2017-09-13\", end=\"2017-11-13\", freq=\"1D\").strftime(\"%Y-%m-%d\").to_list()\n",
    "    num_pred = np.clip(_model.predict(features, batch_size=1, verbose=1).astype(int)[:,-1,:] , a_min=0, a_max=None)\n",
    "    index = df_ds.index  # np.char.decode(features[0].numpy().astype(bytes))\n",
    "    ret = pd.DataFrame(num_pred, columns=out_date, index=index).stack().rename(\"Visits\")\n",
    "    ret.index = [ii[0]+\"_\"+ii[1] for ii in ret.index]\n",
    "    return ret\n",
    "\n",
    "features = [tf.convert_to_tensor(df_ds.index), df_ds.values]\n",
    "Visits_pred = output_form(features, model_rnn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [tf.convert_to_tensor(df_ds.index), df_ds.values, tf.convert_to_tensor(median_en)]\n",
    "\n",
    "Visits_pred = output_form(features, mixed_model)\n",
    "Visits_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key.loc[Visits_pred.index, \"Visits\"] = Visits_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key.to_csv(\"subm_mixed.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# load kaggle environment if in google colab\n",
    "from google.colab import files\n",
    "files.upload() #upload kaggle.json\n",
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -f subm_mixed.csv -m \"mixed med/lin (elt wise best)\"  web-traffic-time-series-forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Visits_pred, key ,features\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
